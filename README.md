# Chaos Classification: Neural Network vs Lyapunov

## ğŸ“Œ Abstract  
Chaos theory describes the unpredictable yet deterministic nature of many physical systems, with applications in physics, engineering, and finance. The **Lyapunov exponent** is a widely used mathematical tool for classifying chaotic behavior, but can **deep learning outperform traditional methods?**  
This project explores whether **Neural Networks (NNs)** can provide a superior alternative for chaos detection, leveraging **SHM (Simple Harmonic Motion) & Double Pendulum** as test cases. Additionally, we employ **SHAP (SHapley Additive exPlanations)** to interpret model decisions, bridging the gap between deep learning and explainable AI.

## ğŸ“– Introduction  
Chaos is an inherent property of many dynamical systems where small changes in initial conditions can lead to vastly different outcomes. Traditionally, the **Lyapunov exponent** is used to determine whether a system exhibits chaos (positive exponent) or remains predictable (negative or zero exponent). However, this approach relies on analytical methods that may be infeasible for complex real-world data.

In contrast, machine learningâ€”particularly **neural networks**â€”can learn from observed patterns and classify chaotic vs. non-chaotic systems without explicit equations. This research investigates:

âœ… Can neural networks **outperform** Lyapunov exponents in classifying chaos?  
âœ… How does **Explainable AI (SHAP)** contribute to understanding chaos classification?  
âœ… How does deep learning compare to **traditional mathematical approaches**?  

## âš¡ Key Contributions
âœ… **Neural Network Classifier** â€“ Trained on dynamical system trajectories to detect chaos.  
âœ… **Lyapunov Exponent Baseline** â€“ Traditional approach used for comparison.  
âœ… **SHAP Explainability** â€“ Analyzing how NNs make chaos classification decisions.  
âœ… **Extensive Evaluation** â€“ Accuracy, precision, recall, F1-score, and visualizations.  

---

## ğŸ“‚ Theoretical Background
### ğŸ”¹ Lyapunov Exponent & Chaos
The **Lyapunov exponent (Î»)** measures the sensitivity of a system to initial conditions. It is defined as:
\[ 
\lambda = \lim_{{t \to \infty}} \frac{1}{t} \sum_{i=1}^{t} \ln \left| \frac{dx_i}{dx_0} \right| 
\]
If \( \lambda > 0 \), the system is chaotic, meaning small perturbations lead to exponential divergence. If \( \lambda \leq 0 \), the system is stable or periodic.

---

## ğŸ“‚ Dataset & Methodology
### ğŸ”¹ Dataset
We use simulated data from **SHM (Simple Harmonic Motion) and Double Pendulum systems**, generating time-series trajectories and extracting key features such as:
- Displacement, velocity, and acceleration
- Angular momentum (for pendulum systems)
- Phase space embedding

### ğŸ”¹ Neural Network Model
- **Feedforward Neural Network** with ReLU activation.
- **L2 Regularization & Dropout** to prevent overfitting.
- **Adam Optimizer** for adaptive learning.
- **Early Stopping** to optimize training performance.

### ğŸ”¹ Lyapunov Baseline Classifier
- Computes **Lyapunov exponent** and classifies based on \( \lambda > 0 \).
- Serves as a benchmark for machine learning performance.

---

## ğŸ“Š Experimental Results & Analysis
Our experiments show that deep learning significantly outperforms Lyapunov exponent classification. We also apply **SHAP explainability** to analyze how different features contribute to predictions.

| Model  | Accuracy (%) | Precision (%) | Recall (%) | F1-Score (%) |
|--------|-------------|--------------|------------|--------------|
| **Neural Network** | 90.25 | 87.76 | 94.75 | 90.19 |
| **Lyapunov Exponent** | 50.20 | 50.00 | 50.00 | 50.00 |

### **Key Observations**
ğŸ“Œ **Neural networks generalize well**, whereas Lyapunov exponents are rigid for unseen conditions.  
ğŸ“Œ **SHAP analysis** reveals that velocity and angular momentum are critical for chaos detection.  
ğŸ“Œ **Higher-dimensional embeddings improve NN performance.**  

---

## ğŸ“Š Visualizations & Explainability
### Double Pendulum Motion (Chaotic Example)
![Double Pendulum](graphs/double_pendulum_motion_chaotic.png)

### SHM Motion (Non-Chaotic Example)
![SHM](graphs/shm_nonchaotic.png)

### SHAP Feature Importance
![SHAP](graphs/meanshapvalue.png)

### Confusion Matrix
![Confusion Matrix](graphs/confusionmatrix.png)

### ROC Curve
![ROC](graphs/roc_curve.png)

---

## ğŸš€ Future Work & Research Directions
ğŸ”¹ Apply chaos detection to **weather prediction systems** (atmospheric turbulence modeling).  
ğŸ”¹ Use chaos classification for **financial market instability detection**.  
ğŸ”¹ Expand dataset to include **Lorenz Attractor & Logistic Map**.  
ğŸ”¹ Explore **Recurrent Neural Networks (RNNs) and Transformers** for time-series classification.  
ğŸ”¹ Enhance interpretability using **LIME & Counterfactual Explanations**.  

---

## ğŸ“œ References
ğŸ”¹ Sprott, J. C. (2003). *Chaos and Time-Series Analysis*  
ğŸ”¹ Strogatz, S. H. (2018). *Nonlinear Dynamics and Chaos*  
ğŸ”¹ Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*  

---

## ğŸ“Œ Installation & Usage
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/chaos-classification.git  
cd chaos-classification  
```
### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt  
```
### 3ï¸âƒ£ Run the Neural Network Model
```bash
python chaos_nn_classifier.py  
```

---

## ğŸ“¬ Contact & Contributions
ğŸ“© **Want to contribute?** Open an **Issue** or submit a **Pull Request**.  
ğŸ’¡ **For inquiries, reach out via email or GitHub Discussions.**  

---

### ğŸ”¥ *"In chaos, AI finds patterns where math sees randomness!"*  
